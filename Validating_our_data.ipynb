{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8753bdc3",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Integrated project: Validating our data\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "In this Code Challenge we’re diving into the agricultural dataset again to continue to validate our data. Before we do that, we’re pausing to build a data pipeline that will ingest and clean our data with the press of a button, cleaning up our code significantly. Once that’s ready, we’ll complete our data validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944ccbc",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e633f",
   "metadata": {},
   "source": [
    "Here we are diving right into the code without outlining the step by step process.\n",
    "\n",
    "So what's the plan? \n",
    "1. Create a null hypothesis.\n",
    "1. Import the `MD_agric_df` dataset and clean it up.\n",
    "1. Import the weather data.\n",
    "1. Map the weather data to the field data.\n",
    "1. Calculate the means of the weather station dataset and the means of the main dataset.\n",
    "2. Calculate all the parameters we need to do a t-test. \n",
    "3. Interpret our results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc088a0-1215-4af8-834e-16a0c27e8414",
   "metadata": {},
   "source": [
    "# Validating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b6ae70-5c25-4f09-833c-972c56b1cf6e",
   "metadata": {},
   "source": [
    "So we finally have working modules that now automatically pull data from the database  (or the web), process it, clean it, and return our starting DataFrame. Before we jump in and analyse the data, let's pause for a second and ask: Did the changes actually get applied? Did we correct the elevation data, did we rename the columns? We could go back to the old ways, and create queries to check, but a better way is to **test our dataset**. \n",
    "\n",
    "Let's get the data in first. Remember to use your `config_params` dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147be850",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e655574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.field_data_processor import FieldDataProcessor\n",
    "from scripts.weather_data_processor import WeatherDataProcessor\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2937ec",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30fc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_station_df = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv\")\n",
    "weather_station_mapping_df = pd.read_csv(\"https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv\")\n",
    "\n",
    "config_params = {\n",
    "    \"sql_query\": \"\"\"SELECT *\n",
    "        FROM geographic_features\n",
    "        LEFT JOIN weather_features USING (Field_ID)\n",
    "        LEFT JOIN soil_and_crop_features USING (Field_ID)\n",
    "        LEFT JOIN farm_management_features USING (Field_ID)\n",
    "        \"\"\", \n",
    "    \"db_path\": 'sqlite:///database/Maji_Ndogo_farm_survey_small.db', # Insert the db_path of the database\n",
    "    \"columns_to_rename\": {'Annual_yield': 'Crop_type', 'Crop_type': 'Annual_yield'},# Insert the disctionary of columns we want to swop the names of\n",
    "    \"values_to_rename\": {'cassaval': 'cassava', 'wheatn': 'wheat', 'teaa': 'tea'}, # Insert the croptype renaming dictionary\n",
    "    \"weather_csv_path\": 'https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv', # Insert the weather data CSV here\n",
    "    \"weather_mapping_csv\": 'https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_data_field_mapping.csv', # Insert the weather data mapping CSV here   # Add two new keys\n",
    "    \"weather_csv_path\": 'https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Maji_Ndogo/Weather_station_data.csv', # Insert the URL for the weather station data\n",
    "    \"regex_patterns\" : {\n",
    "        'Rainfall': r'(\\d+(\\.\\d+)?)\\s?mm',\n",
    "        'Temperature': r'(\\d+(\\.\\d+)?)\\s?C',\n",
    "        'Pollution_level': r'=\\s*(-?\\d+(\\.\\d+)?)|Pollution at \\s*(-?\\d+(\\.\\d+)?)'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72163fa3",
   "metadata": {},
   "source": [
    "**Check if our file executes correctly**\n",
    "\n",
    "Before we actually get to the analysis part, take a moment to notice how much simpler this data import is now. It feels like a lot of work, but now one cell of code imports and cleans all of our data.\n",
    "\n",
    "Let's get the data in first. Remember to use your `config_params` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4af300e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 18:55:59,503 - data_ingestion - INFO - Database engine created successfully.\n",
      "2024-03-01 18:55:59,697 - data_ingestion - INFO - Query executed successfully.\n",
      "2024-03-01 18:55:59,698 - scripts.field_data_processor.FieldDataProcessor - INFO - Successfully loaded data.\n",
      "2024-03-01 18:55:59,700 - scripts.field_data_processor.FieldDataProcessor - INFO - Swapped columns: Annual_yield with Crop_type\n",
      "2024-03-01 18:56:04,807 - data_ingestion - INFO - CSV file read successfully from the web.\n",
      "2024-03-01 18:56:07,370 - data_ingestion - INFO - CSV file read successfully from the web.\n",
      "2024-03-01 18:56:07,374 - scripts.weather_data_processor.WeatherDataProcessor - INFO - Successfully loaded weather station data from the web.\n",
      "2024-03-01 18:56:07,486 - scripts.weather_data_processor.WeatherDataProcessor - INFO - Messages processed and measurements extracted.\n",
      "2024-03-01 18:56:07,487 - scripts.weather_data_processor.WeatherDataProcessor - INFO - Data processing completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Temperature', 'Pollution_level', 'Rainfall'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_params = config_params\n",
    "\n",
    "field_processor = FieldDataProcessor(config_params)\n",
    "field_processor.process()\n",
    "field_df = field_processor.df\n",
    "\n",
    "weather_processor = WeatherDataProcessor(config_params)\n",
    "weather_processor.process()\n",
    "weather_df = weather_processor.weather_df\n",
    "\n",
    "# Rename 'Ave_temps' in field_df to 'Temperature' to match weather_df\n",
    "field_df.rename(columns={'Ave_temps': 'Temperature'}, inplace=True)\n",
    "\n",
    "weather_df['Measurement'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e121864",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```python\n",
    "<Timestamp> - data_ingestion - INFO - Database engine created successfully.\n",
    "<Timestamp> - data_ingestion - INFO - Query executed successfully.\n",
    "<Timestamp> - scripts.field_data_processor.FieldDataProcessor - INFO - Successfully loaded data.\n",
    "<Timestamp> - scripts.field_data_processor.FieldDataProcessor - INFO - Swapped columns: Annual_yield with Crop_type\n",
    "<Timestamp> - data_ingestion - INFO - CSV file read successfully from the web.\n",
    "<Timestamp> - data_ingestion - INFO - CSV file read successfully from the web.\n",
    "<Timestamp> - scripts.weather_data_processor.WeatherDataProcessor - INFO - Successfully loaded weather station data from the web.\n",
    "<Timestamp> - scripts.weather_data_processor.WeatherDataProcessor - INFO - Messages processed and measurements extracted.\n",
    "<Timestamp> - scripts.weather_data_processor.WeatherDataProcessor - INFO - Data processing completed.\n",
    "\n",
    "array(['Temperature', 'Pollution_level', 'Rainfall'], dtype=object)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d54794",
   "metadata": {},
   "source": [
    "### Validating our data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a9dec5",
   "metadata": {},
   "source": [
    "Before we jump in and analyse the data, let's pause for a second and ask: Did the changes actually get applied? Did we correct the elevation data, did we rename the columns? We could go back to the old ways, and create queries to check, but a better way is to **test our dataset**. \n",
    "\n",
    "There should be a `validate_data.py` file in the notebook directory. This is a `pytest` script that does a couple of tests to see if the data we're expecting, is what we actually have. Have a look at the test script, and try to understand what we're testing.\n",
    "\n",
    "`pytest` normally runs from the command line because it is set up to be automated. To test the data, we have to give `pytest` access to that data. The simplest way to do this is by creating CSV files, importing them into `validate_data.py`, and running the tests.\n",
    "\n",
    "The following code creates CSV files, runs `pytest` in the terminal using `!pytest validate_data.py -v`, and deletes the CSV files once the test is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5456e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.8.18, pytest-8.0.2, pluggy-1.4.0 -- C:\\ProgramData\\anaconda3\\envs\\sql\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: C:\\Users\\Pauline PC\\Documents\\ALXdata\\python\\integrated_project\n",
      "plugins: anyio-4.2.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 9 items\n",
      "\n",
      "test/validate_data.py::test_read_weather_DataFrame_shape \u001b[32mPASSED\u001b[0m\u001b[32m          [ 11%]\u001b[0m\n",
      "test/validate_data.py::test_read_field_DataFrame_shape \u001b[32mPASSED\u001b[0m\u001b[32m            [ 22%]\u001b[0m\n",
      "test/validate_data.py::test_weather_dataframe_columns \u001b[32mPASSED\u001b[0m\u001b[32m             [ 33%]\u001b[0m\n",
      "test/validate_data.py::test_field_dataframe_columns \u001b[32mPASSED\u001b[0m\u001b[32m               [ 44%]\u001b[0m\n",
      "test/validate_data.py::test_crop_types_are_valid \u001b[32mPASSED\u001b[0m\u001b[32m                  [ 55%]\u001b[0m\n",
      "test/validate_data.py::test_field_dataframe_non_negative_elevation \u001b[32mPASSED\u001b[0m\u001b[32m [ 66%]\u001b[0m\n",
      "test/validate_data.py::test_positive_rainfall_values \u001b[32mPASSED\u001b[0m\u001b[32m              [ 77%]\u001b[0m\n",
      "test/validate_data.py::test_weather_dataframe_not_empty \u001b[32mPASSED\u001b[0m\u001b[32m           [ 88%]\u001b[0m\n",
      "test/validate_data.py::test_field_dataframe_not_empty \u001b[32mPASSED\u001b[0m\u001b[32m             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================= \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 37.16s\u001b[0m\u001b[32m ==============================\u001b[0m\n",
      "Deleted sampled_weather_df.csv\n",
      "Deleted sampled_field_df.csv\n"
     ]
    }
   ],
   "source": [
    "# !pip install pytest\n",
    "weather_df.to_csv('sampled_weather_df.csv', index=False)\n",
    "field_df.to_csv('sampled_field_df.csv', index=False)\n",
    "\n",
    "!pytest test/validate_data.py -v\n",
    "\n",
    "import os# Define the file paths\n",
    "weather_csv_path = 'sampled_weather_df.csv'\n",
    "field_csv_path = 'sampled_field_df.csv'\n",
    "\n",
    "# Delete sampled_weather_df.csv if it exists\n",
    "if os.path.exists(weather_csv_path):\n",
    "    os.remove(weather_csv_path)\n",
    "    print(f\"Deleted {weather_csv_path}\")\n",
    "else:\n",
    "    print(f\"{weather_csv_path} does not exist.\")\n",
    "\n",
    "# Delete sampled_field_df.csv if it exists\n",
    "if os.path.exists(field_csv_path):\n",
    "    os.remove(field_csv_path)\n",
    "    print(f\"Deleted {field_csv_path}\")\n",
    "else:\n",
    "    print(f\"{field_csv_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab08492",
   "metadata": {},
   "source": [
    "**Expected output:**\n",
    "\n",
    "```python\n",
    "============================ test session starts =============================\n",
    "platform win32 -- Python 3.12.1, pytest-8.0.0, pluggy-1.4.0 -- ...\n",
    "cachedir: .pytest_cache\n",
    "rootdir: ...\n",
    "plugins: anyio-4.2.0\n",
    "collecting ... collected 9 items\n",
    "\n",
    "test/validate_data.py::test_read_weather_DataFrame_shape PASSED          [ 11%]\n",
    "test/validate_data.py::test_read_field_DataFrame_shape PASSED            [ 22%]\n",
    "test/validate_data.py::test_weather_dataframe_columns PASSED             [ 33%]\n",
    "test/validate_data.py::test_field_dataframe_columns PASSED               [ 44%]\n",
    "test/validate_data.py::test_crop_types_are_valid PASSED                  [ 55%]\n",
    "test/validate_data.py::test_field_dataframe_non_negative_elevation PASSED [ 66%]\n",
    "test/validate_data.py::test_positive_rainfall_values PASSED              [ 77%]\n",
    "test/validate_data.py::test_weather_dataframe_not_empty PASSED           [ 88%]\n",
    "test/validate_data.py::test_field_dataframe_not_empty PASSED             [100%]\n",
    "\n",
    "============================== warnings summary ===============================\n",
    "..\\..\\..\\..\\..\\..\\..\\..\\anaconda3\\envs\\Latest\\Lib\\site-packages\\dateutil\\tz\\tz.py:37\n",
    "  ...: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
    "    EPOCH = datetime.datetime.utcfromtimestamp(0)\n",
    "\n",
    "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
    "\n",
    "============================= 9 passed in 38.85s ==============================\n",
    "\n",
    "Deleted sampled_weather_df.csv\n",
    "Deleted sampled_field_df.csv\n",
    "```\n",
    "\n",
    ">⚠️ Depending on the version of Python, there may be various warnings like the one above. These are normally `DeprecationWarnings` so we can safely ignore these for now. We're interested in whether all the dataset tests passed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e09daa",
   "metadata": {},
   "source": [
    "Great! Now we know our data resembles what we expect! As our project evolves we may have to add more module functionality or create more rigorous tests of the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7e9d8",
   "metadata": {},
   "source": [
    "Ok, now we can circle back to the start. As I mentioned, setting a tolerance might have been a simple way to measure if our field data and weather data agree, but we didn't take into account if either dataset was spread out.\n",
    "\n",
    "I hope you have some idea of the problem, but we need to tell this story anyway, so hopefully, I can convince you I made an error last time, by the time we're done.\n",
    "\n",
    "Back to our initial plan:\n",
    "\n",
    "1. Create a null hypothesis.\n",
    "1. Import the `MD_agric_df` dataset and clean it up.\n",
    "1. Import the weather data.\n",
    "1. Map the weather data to the field data.\n",
    "1. Calculate the means of the weather station dataset and the means of the main dataset.\n",
    "2. Calculate all the parameters we need to do a t-test. \n",
    "3. Interpret our results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fbcc03",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b650117",
   "metadata": {},
   "source": [
    "So what are we testing with our null hypothesis $H_0$? Well, we want to know if our field data is representing the reality in Maji Ndogo by looking at an independent set of data. If our field data (means) are the same as the weather data (means), then it indicates no significant difference between the datasets. We're essentially saying that any difference we see between these means is because of randomness. However, if the means differ significantly, we'll know there is a reason for it, and that it is not just a random fluctuation in the data. \n",
    "\n",
    "<br>\n",
    "\n",
    "Given a significance level $\\alpha$ of 0.05 for a two-tailed test, we have the following conditions for our hypothesis test at a 95% confidence interval:\n",
    "\n",
    "- $H_0$: There is no significant difference between the means of the two datasets. This is expressed as $\\mu_{field} = \\mu_{weather}$.\n",
    "\n",
    "- $H_a$: There is a significant difference between the means of the two datasets. This is expressed as $\\mu_{field} \\neq \\mu_{weather}$.\n",
    "\n",
    "<br>\n",
    "\n",
    "If the p-value obtained from the test:\n",
    "- is less than or equal to the significance level, so $p \\leq \\alpha$, we reject the null hypothesis.\n",
    "- is larger than the significance level, so $p > \\alpha$, we cannot reject the null hypothesis, as we cannot find a statistically significant difference between the datasets at the 95% confidence level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd1bf54",
   "metadata": {},
   "source": [
    "Now, let's code it out. \n",
    "\n",
    "First, we're going to import all of the packages and define a few variables. You might notice we're importing a new method, `.ttest_ind()`. This method takes in two data columns and calculates means, variance, and returns the the t- and p-statistics. So our t-test is reduced to one line. Since our alternative hypothesis does not make a claim of greater or less than, we will use the two-sided t-test, by adding  the `alternative = 'two-sided'` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5833b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "# Now, the measurements_to_compare can directly use 'Temperature', 'Rainfall', and 'Pollution_level'\n",
    "measurements_to_compare = ['Temperature', 'Rainfall', 'Pollution_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f085a",
   "metadata": {},
   "source": [
    "Let's pause for a second and clarify what exactly we're comparing. \n",
    "\n",
    "We want to compare the means of the temperature, rainfall, and pollution data, for fields assigned to a specific weather station. So for both datasets, we need to isolate the measurement type and weather station for each data, so we're comparing the correct means.\n",
    "\n",
    "Let's break down what we need to do:\n",
    "1. We need to filter both `field_df` and `weather_df` based on the given station ID and measurement. We can use `filter_field_data(df, station_id, measurement)` and `filter_weather_data(df, station_id, measurement)`.  \n",
    "2. We need to perform a t-test to conduct the t-test on the filtered data. So we're going to use `ttest_ind(data_col1, data_col2, equal_var=False)` from `scipy.stats`.\n",
    "3. `print_ttest_results(station_id, measurement, p_val, alpha)` to interpret and print the results from the t-test.\n",
    "\n",
    "We'll first define these functions, focusing on `Temperature` for `station ID = 0`. Then, we'll integrate these functions into a loop that iterates over each station ID and measurement type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe83fc",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "⚙️ **Task:** Create a `filter_field_data` function that takes in the `field_df` DataFrame, the `station_id`, and `measurement` type, and retuns a **single column** (series) of data filtered by the `station_id`, and `measurement`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b52be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## START FUNCTION\n",
    "def filter_field_data(df, station_id, measurement):\n",
    "    \"\"\"\n",
    "    Filters field data based on station_id and measurement.\n",
    "\n",
    "    Args:\n",
    "    - df (pandas.DataFrame): The DataFrame containing field data.\n",
    "    - station_id (str): The ID of the weather station.\n",
    "    - measurement (str): The type of measurement to filter.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.Series: A single column (series) of data filtered by station_id and measurement.\n",
    "    \"\"\"\n",
    "    # Filter on players older than 30 and overall rating greater than 90.\n",
    "    df = df[df['Weather_station'] == station_id][measurement]\n",
    "    return df\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be8aba",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Input 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123ae3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       13.35\n",
       "2       13.30\n",
       "8       12.80\n",
       "10      13.70\n",
       "14      13.35\n",
       "        ...  \n",
       "5627    13.30\n",
       "5630    14.25\n",
       "5632    11.00\n",
       "5638    13.30\n",
       "5642    12.85\n",
       "Name: Temperature, Length: 1375, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example for station ID 0 and Temperature\n",
    "station_id = 0\n",
    "alpha = 0.05\n",
    "measurement = 'Temperature'\n",
    "\n",
    "# Filter data for the specific station and measurement\n",
    "field_values = filter_field_data(field_df, station_id, measurement)\n",
    "field_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1723c0",
   "metadata": {},
   "source": [
    "**Expected outcome:**\n",
    "\n",
    "```python\n",
    "1       13.35\n",
    "2       13.30\n",
    "8       12.80\n",
    "10      13.70\n",
    "14      13.35\n",
    "        ...  \n",
    "5627    13.30\n",
    "5630    14.25\n",
    "5632    11.00\n",
    "5638    13.30\n",
    "5642    12.85\n",
    "Name: Temperature, Length: 1375, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb677fc4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Input 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99f9178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1375,), First value: 13.35 \n"
     ]
    }
   ],
   "source": [
    "# Example for station ID 0 and Temperature\n",
    "station_id = 0\n",
    "alpha = 0.05\n",
    "measurement = 'Temperature'\n",
    "\n",
    "# Filter data for the specific station and measurement\n",
    "field_values = filter_field_data(field_df, station_id, measurement)\n",
    "print(f\"Shape: {field_values.shape}, First value: {field_values.iloc[0]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb2a378",
   "metadata": {},
   "source": [
    "**Expected outcome:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff140a",
   "metadata": {},
   "source": [
    "`Shape: (1375,), First value: 13.35 `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ac4c9",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "⚙️ **Task:** Create a data filter function that takes in the `weather_df` DataFrame, the `station_id`, and `measurement` type, and returns a **single column** (series) of data filtered by the `station_id`, and `measurement`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50110261",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "\n",
    "def filter_weather_data(df, station_id, measurement):\n",
    "    \"\"\"\n",
    "    Filters a weather DataFrame based on the given station_id and measurement.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The input weather DataFrame.\n",
    "    - station_id (int): The station ID to filter by.\n",
    "    - measurement (str): The measurement type to filter by.\n",
    "\n",
    "    Returns:\n",
    "    - pd.Series: A single column (series) of data filtered by the station_id and measurement.\n",
    "    \"\"\"\n",
    "    df = df[(df['Weather_station_ID'] == station_id) & (df['Measurement'] == measurement)]['Value']\n",
    "    # print(df.head(2))\n",
    "    return df\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d919e41",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "**Input 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a948c941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       12.82\n",
       "2       14.53\n",
       "29      14.28\n",
       "32      12.87\n",
       "67      13.13\n",
       "        ...  \n",
       "1804    12.77\n",
       "1805    14.13\n",
       "1817    13.14\n",
       "1833    14.14\n",
       "1834    13.61\n",
       "Name: Value, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example for station ID 0 and Temperature\n",
    "station_id = 0\n",
    "alpha = 0.05\n",
    "measurement = 'Temperature'\n",
    "\n",
    "# Filter data for the specific station and measurement\n",
    "\n",
    "weather_values = filter_weather_data(weather_df, station_id, measurement)\n",
    "weather_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092f164",
   "metadata": {},
   "source": [
    "**Expected outcome:**\n",
    "\n",
    "```python\n",
    "0       12.82\n",
    "2       14.53\n",
    "29      14.28\n",
    "32      12.87\n",
    "67      13.13\n",
    "        ...  \n",
    "1804    12.77\n",
    "1805    14.13\n",
    "1817    13.14\n",
    "1833    14.14\n",
    "1834    13.61\n",
    "Name: Value, Length: 100, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9438d96",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "**Input 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "581e8064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (100,), First value: 12.82\n"
     ]
    }
   ],
   "source": [
    "# Example for station ID 0 and Temperature\n",
    "station_id = 0\n",
    "alpha = 0.05\n",
    "measurement = 'Temperature'\n",
    "\n",
    "# Filter data for the specific station and measurement\n",
    "\n",
    "weather_values = filter_weather_data(weather_df, station_id, measurement)\n",
    "\n",
    "print(f\"Shape: {weather_values.shape}, First value: {weather_values.iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef3c1b",
   "metadata": {},
   "source": [
    "**Expected outcome:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02a97d",
   "metadata": {},
   "source": [
    "`Shape: (100,), First value: 12.82 `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffb1692",
   "metadata": {},
   "source": [
    "⚙️ **Task:** Create a function that calculates the t-statistic and p-value. The function should accept two **single columns** of data and return a tuple of the t-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8e45878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def run_ttest(Column_A, Column_B):\n",
    "    \"\"\"\n",
    "    Calculates the t-statistic and p-value for two sets of data.\n",
    "\n",
    "    Parameters:\n",
    "    - Column_A (pd.Series or iterable): First set of data.\n",
    "    - Column_B (pd.Series or iterable): Second set of data.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the t-statistic and p-value.\n",
    "    \"\"\"\n",
    "    t_statistic, p_value = ttest_ind(Column_A, Column_B, equal_var=False)\n",
    "    return t_statistic, p_value\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80bb12",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "**Input:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b3b07adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-stat: -0.11632, p-value: 0.90761\n"
     ]
    }
   ],
   "source": [
    "# Example for station ID 0 and Temperature\n",
    "station_id = 0\n",
    "alpha = 0.05\n",
    "measurement = 'Temperature'\n",
    "\n",
    "# Filter data for the specific station and measurement\n",
    "field_values = filter_field_data(field_df, station_id, measurement)\n",
    "weather_values = filter_weather_data(weather_df, station_id, measurement)\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_val = run_ttest(field_values, weather_values)\n",
    "print(f\"T-stat: {t_stat:.5f}, p-value: {p_val:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24a913",
   "metadata": {},
   "source": [
    "**Expected outcome:**\n",
    "\n",
    "`T-stat: -0.11632, p-value: 0.90761`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ae8fcf",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "⚙️ **Task:** Replace the **\\<MISSING CODE>** to print out the t-test result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c884eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "\n",
    "def print_ttest_results(station_id, measurement, p_val, alpha):\n",
    "    \"\"\"\n",
    "    Interprets and prints the results of a t-test based on the p-value.\n",
    "    \"\"\"\n",
    "    if p_val <= alpha:\n",
    "        print(f\"   Significant difference in {measurement} detected at Station  {station_id}, (P-Value: {p_val:.5f} < {alpha}). Null hypothesis rejected.\")\n",
    "    else:\n",
    "        print(f\"   No significant difference in {measurement} detected at Station  {station_id}, (P-Value: {p_val:.5f} > {alpha}). Null hypothesis not rejected.\")\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2651a66d",
   "metadata": {},
   "source": [
    "**Input:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "59929bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No significant difference in Temperature detected at Station  0, (P-Value: 0.90761 > 0.05). Null hypothesis not rejected.\n"
     ]
    }
   ],
   "source": [
    "# Example for station ID 0 and Temperature\n",
    "station_id = 0\n",
    "\n",
    "measurement = 'Temperature'\n",
    "\n",
    "# Filter data for the specific station and measurement\n",
    "field_values = filter_field_data(field_df, station_id, measurement)\n",
    "weather_values = filter_weather_data(weather_df, station_id, measurement)\n",
    "\n",
    "# Perform t-test\n",
    "t_stat, p_val = run_ttest(field_values, weather_values)\n",
    "print_ttest_results(station_id, measurement, p_val, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02656fe5",
   "metadata": {},
   "source": [
    "**Expected outcome:**\n",
    "\n",
    "`No significant difference in Temperature detected (P-Value: 0.90761 > 0.05). Null hypothesis not rejected.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353c517",
   "metadata": {},
   "source": [
    "Now we can put it all together in a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e22bed",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "⚙️ **Task:** Create a function that loops over `measurements_to_compare` and all `station_id`, perform a t-test and print the results. The function should accept `field_df`, `weather_df`, `list_measurements_to_compare`, `alpha`. the value of `alpha` should default to a value of 0.05. Hint: use `print_ttest_results()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "89bf6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def hypothesis_results(field_df, weather_df, list_measurements_to_compare, alpha = 0.05):\n",
    "    \"\"\"\n",
    "    Performs t-tests on specified measurements for each weather station and prints the results.\n",
    "\n",
    "    Parameters:\n",
    "    - field_df (pd.DataFrame): DataFrame containing field data.\n",
    "    - weather_df (pd.DataFrame): DataFrame containing weather data.\n",
    "    - list_measurements_to_compare (list): List of measurement types to compare.\n",
    "    - alpha (float, optional): Significance level. Default is 0.05.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    for station_id in sorted(weather_df['Weather_station_ID'].unique()):\n",
    "        for measurement in list_measurements_to_compare:\n",
    "            field_values = filter_field_data(field_df, station_id, measurement)\n",
    "            weather_values = filter_weather_data(weather_df, station_id, measurement)\n",
    "            t_statistic, p_value = run_ttest(field_values, weather_values)\n",
    "            print_ttest_results(station_id, measurement, p_value, alpha)\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea120b",
   "metadata": {},
   "source": [
    "**Input:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1fafd76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No significant difference in Temperature detected at Station  0, (P-Value: 0.90761 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Rainfall detected at Station  0, (P-Value: 0.21621 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Pollution_level detected at Station  0, (P-Value: 0.56418 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Temperature detected at Station  1, (P-Value: 0.47241 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Rainfall detected at Station  1, (P-Value: 0.54499 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Pollution_level detected at Station  1, (P-Value: 0.24410 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Temperature detected at Station  2, (P-Value: 0.88671 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Rainfall detected at Station  2, (P-Value: 0.36466 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Pollution_level detected at Station  2, (P-Value: 0.99388 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Temperature detected at Station  3, (P-Value: 0.66445 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Rainfall detected at Station  3, (P-Value: 0.39847 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Pollution_level detected at Station  3, (P-Value: 0.15466 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Temperature detected at Station  4, (P-Value: 0.88575 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Rainfall detected at Station  4, (P-Value: 0.33237 > 0.05). Null hypothesis not rejected.\n",
      "   No significant difference in Pollution_level detected at Station  4, (P-Value: 0.21508 > 0.05). Null hypothesis not rejected.\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "hypothesis_results(field_df, weather_df, measurements_to_compare, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1b7b0",
   "metadata": {},
   "source": [
    "**Expected outcome:**\n",
    "```python \n",
    "   No significant difference in Temperature detected at Station 0, (P-Value: 0.90761 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Rainfall detected at Station 0, (P-Value: 0.21621 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Pollution_level detected at Station 0, (P-Value: 0.56418 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Temperature detected at Station 1, (P-Value: 0.47241 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Rainfall detected at Station 1, (P-Value: 0.54499 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Pollution_level detected at Station 1, (P-Value: 0.24410 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Temperature detected at Station 2, (P-Value: 0.88671 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Rainfall detected at Station 2, (P-Value: 0.36466 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Pollution_level detected at Station 2, (P-Value: 0.99388 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Temperature detected at Station 3, (P-Value: 0.66445 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Rainfall detected at Station 3, (P-Value: 0.39847 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Pollution_level detected at Station 3, (P-Value: 0.15466 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Temperature detected at Station 4, (P-Value: 0.88575 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Rainfall detected at Station 4, (P-Value: 0.33237 > 0.05). Null hypothesis not rejected.\n",
    "   No significant difference in Pollution_level detected at Station 4, (P-Value: 0.21508 > 0.05). Null hypothesis not rejected.\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d75778",
   "metadata": {},
   "source": [
    "Great! There we go. For all of our measurements the p-value > alpha, so there is not enough evidence to reject the null hypothesis. This means we have no evidence to suggest that the weather data is different from the field data. This makes us confident that our field data, at least in terms of temperature, rainfall, and pollution level is reflecting the reality. \n",
    "\n",
    "Why was this important? Well, we saw from the EDA that there were some relationships, and possible correlations with the standard yield, but we really can't say what affects a crop's success, because all of them seemed to. In a sense, we as humans could not clearly see the relationships, if we were given a set of conditions like rainfall, pH, and crop type, we could not reliably estimate what the standard yield of a crop is, because the relationships are hard to understand.\n",
    "\n",
    "So our next step is to allow a machine to look for patterns, which is Machine Learning (ML). Computers are not limited to three dimensions, can calculate for hours, and find hidden patterns we cannot. Machine learning follows the basic principle across computational domains; junk in, junk out. We needed to make sure that the data we're feeding into ML models is accurate. Now we know, and we're ready for the next step. \n",
    "\n",
    "You must have been itching to get into AI, so we'll dive in soon.\n",
    "\n",
    "Until then, look after yourself!\n",
    "Saana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
